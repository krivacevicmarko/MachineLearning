{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "lyYZ107VBnxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ist8x7QY9iie",
        "outputId": "4ba684d4-fe2d-4edf-9eab-51ac62b756c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2200, 8)\n",
            "Epoch: 1/100| Avg loss: 2.20318\n",
            "Epoch: 2/100| Avg loss: 1.50684\n",
            "Epoch: 3/100| Avg loss: 1.11558\n",
            "Epoch: 4/100| Avg loss: 0.87966\n",
            "Epoch: 5/100| Avg loss: 0.73006\n",
            "Epoch: 6/100| Avg loss: 0.61903\n",
            "Epoch: 7/100| Avg loss: 0.53142\n",
            "Epoch: 8/100| Avg loss: 0.46530\n",
            "Epoch: 9/100| Avg loss: 0.40968\n",
            "Epoch: 10/100| Avg loss: 0.35632\n",
            "Epoch: 11/100| Avg loss: 0.30576\n",
            "Epoch: 12/100| Avg loss: 0.26208\n",
            "Epoch: 13/100| Avg loss: 0.22146\n",
            "Epoch: 14/100| Avg loss: 0.18637\n",
            "Epoch: 15/100| Avg loss: 0.15966\n",
            "Epoch: 16/100| Avg loss: 0.13987\n",
            "Epoch: 17/100| Avg loss: 0.12413\n",
            "Epoch: 18/100| Avg loss: 0.11122\n",
            "Epoch: 19/100| Avg loss: 0.10068\n",
            "Epoch: 20/100| Avg loss: 0.09204\n",
            "Epoch: 21/100| Avg loss: 0.08477\n",
            "Epoch: 22/100| Avg loss: 0.07853\n",
            "Epoch: 23/100| Avg loss: 0.07320\n",
            "Epoch: 24/100| Avg loss: 0.06841\n",
            "Epoch: 25/100| Avg loss: 0.06414\n",
            "Epoch: 26/100| Avg loss: 0.06028\n",
            "Epoch: 27/100| Avg loss: 0.05668\n",
            "Epoch: 28/100| Avg loss: 0.05341\n",
            "Epoch: 29/100| Avg loss: 0.05041\n",
            "Epoch: 30/100| Avg loss: 0.04755\n",
            "Epoch: 31/100| Avg loss: 0.04490\n",
            "Epoch: 32/100| Avg loss: 0.04227\n",
            "Epoch: 33/100| Avg loss: 0.03956\n",
            "Epoch: 34/100| Avg loss: 0.03707\n",
            "Epoch: 35/100| Avg loss: 0.03501\n",
            "Epoch: 36/100| Avg loss: 0.03331\n",
            "Epoch: 37/100| Avg loss: 0.03190\n",
            "Epoch: 38/100| Avg loss: 0.03065\n",
            "Epoch: 39/100| Avg loss: 0.02953\n",
            "Epoch: 40/100| Avg loss: 0.02854\n",
            "Epoch: 41/100| Avg loss: 0.02775\n",
            "Epoch: 42/100| Avg loss: 0.02885\n",
            "Epoch: 43/100| Avg loss: 0.08486\n",
            "Epoch: 44/100| Avg loss: 0.06850\n",
            "Epoch: 45/100| Avg loss: 0.04683\n",
            "Epoch: 46/100| Avg loss: 0.02575\n",
            "Epoch: 47/100| Avg loss: 0.02123\n",
            "Epoch: 48/100| Avg loss: 0.02025\n",
            "Epoch: 49/100| Avg loss: 0.02023\n",
            "Epoch: 50/100| Avg loss: 0.02012\n",
            "Epoch: 51/100| Avg loss: 0.02000\n",
            "Epoch: 52/100| Avg loss: 0.01982\n",
            "Epoch: 53/100| Avg loss: 0.01965\n",
            "Epoch: 54/100| Avg loss: 0.01943\n",
            "Epoch: 55/100| Avg loss: 0.01927\n",
            "Epoch: 56/100| Avg loss: 0.01909\n",
            "Epoch: 57/100| Avg loss: 0.01893\n",
            "Epoch: 58/100| Avg loss: 0.01878\n",
            "Epoch: 59/100| Avg loss: 0.01862\n",
            "Epoch: 60/100| Avg loss: 0.01847\n",
            "Epoch: 61/100| Avg loss: 0.01826\n",
            "Epoch: 62/100| Avg loss: 0.01796\n",
            "Epoch: 63/100| Avg loss: 0.01768\n",
            "Epoch: 64/100| Avg loss: 0.01751\n",
            "Epoch: 65/100| Avg loss: 0.01730\n",
            "Epoch: 66/100| Avg loss: 0.01713\n",
            "Epoch: 67/100| Avg loss: 0.01698\n",
            "Epoch: 68/100| Avg loss: 0.01680\n",
            "Epoch: 69/100| Avg loss: 0.01664\n",
            "Epoch: 70/100| Avg loss: 0.01591\n",
            "Epoch: 71/100| Avg loss: 0.03128\n",
            "Epoch: 72/100| Avg loss: 0.02368\n",
            "Epoch: 73/100| Avg loss: 0.01626\n",
            "Epoch: 74/100| Avg loss: 0.01403\n",
            "Epoch: 75/100| Avg loss: 0.01353\n",
            "Epoch: 76/100| Avg loss: 0.01373\n",
            "Epoch: 77/100| Avg loss: 0.01384\n",
            "Epoch: 78/100| Avg loss: 0.01413\n",
            "Epoch: 79/100| Avg loss: 0.01423\n",
            "Epoch: 80/100| Avg loss: 0.01434\n",
            "Epoch: 81/100| Avg loss: 0.01439\n",
            "Epoch: 82/100| Avg loss: 0.01438\n",
            "Epoch: 83/100| Avg loss: 0.01432\n",
            "Epoch: 84/100| Avg loss: 0.01423\n",
            "Epoch: 85/100| Avg loss: 0.01413\n",
            "Epoch: 86/100| Avg loss: 0.01405\n",
            "Epoch: 87/100| Avg loss: 0.01397\n",
            "Epoch: 88/100| Avg loss: 0.01389\n",
            "Epoch: 89/100| Avg loss: 0.01379\n",
            "Epoch: 90/100| Avg loss: 0.01369\n",
            "Epoch: 91/100| Avg loss: 0.01357\n",
            "Epoch: 92/100| Avg loss: 0.01346\n",
            "Epoch: 93/100| Avg loss: 0.01327\n",
            "Epoch: 94/100| Avg loss: 0.01319\n",
            "Epoch: 95/100| Avg loss: 0.01313\n",
            "Epoch: 96/100| Avg loss: 0.01305\n",
            "Epoch: 97/100| Avg loss: 0.01300\n",
            "Epoch: 98/100| Avg loss: 0.01276\n",
            "Epoch: 99/100| Avg loss: 0.01262\n",
            "Epoch: 100/100| Avg loss: 0.01249\n",
            "Test acc: 0.948\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = np.loadtxt('crop.csv',delimiter=',',skiprows=1,dtype=str,encoding=None)\n",
        "print(data.shape)\n",
        "nitrogen = data[:, 0].astype(float)\n",
        "phosphorus = data[:, 1].astype(float)\n",
        "potassium = data[:, 2].astype(float)\n",
        "temperature = data[:, 3].astype(float)\n",
        "humidity = data[:, 4].astype(float)\n",
        "ph_value = data[:, 5].astype(float)\n",
        "rainfall = data[:, 6].astype(float)\n",
        "y = data[:, 7]\n",
        "class_map = {'Rice': 0,'Maize': 1,'ChickPea': 2,'KidneyBeans': 3,'PigeonPeas': 4,\n",
        "             'MothBeans': 5,'MungBean': 6,'Blackgram': 7,'Lentil': 8,'Pomegranate': 9,\n",
        "             'Banana': 10,'Mango': 11,'Grapes': 12,'Watermelon': 13,'Muskmelon': 14,\n",
        "             'Apple': 15,'Orange': 16,'Papaya': 17,'Coconut': 18,'Cotton': 19,\n",
        "             'Jute': 20,'Coffee': 21}\n",
        "y_numeric = np.array([class_map[label] if label in class_map else label for label in y])\n",
        "X = np.column_stack((nitrogen/100, phosphorus/100, potassium/100, temperature/100, humidity/100, ph_value/100, rainfall/100))\n",
        "\n",
        "train_indices = [list(range(i, i + 80)) for i in range(0, 2200, 100)]\n",
        "train_indices = [index for sublist in train_indices for index in sublist]\n",
        "\n",
        "test_indices = [i for i in range(2200) if i not in train_indices]\n",
        "\n",
        "X_train_manual = X[train_indices]\n",
        "y_train_manual = y_numeric[train_indices]\n",
        "\n",
        "X_test_manual = X[test_indices]\n",
        "y_test_manual = y_numeric[test_indices]\n",
        "\n",
        "nb_train = len(X_train_manual)\n",
        "nb_test = len(y_test_manual)\n",
        "\n",
        "train_x = np.reshape(X_train_manual,[nb_train,-1])\n",
        "test_x = np.reshape(X_test_manual,[nb_test,-1])\n",
        "\n",
        "learning_rate = 0.001\n",
        "nb_epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "nb_input = 1*7\n",
        "nb_hidden1 = 32\n",
        "nb_hidden2 = 32\n",
        "nb_classes = 22\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "w = {\n",
        "    '1': tf.Variable(tf.random.normal([nb_input, nb_hidden1], dtype=tf.float64)),\n",
        "    '2': tf.Variable(tf.random.normal([nb_hidden1, nb_hidden2], dtype=tf.float64)),\n",
        "    'out': tf.Variable(tf.random.normal([nb_hidden2, nb_classes], dtype=tf.float64))\n",
        "}\n",
        "\n",
        "b = {\n",
        "    '1': tf.Variable(tf.random.normal([nb_hidden1], dtype=tf.float64)),\n",
        "    '2': tf.Variable(tf.random.normal([nb_hidden2], dtype=tf.float64)),\n",
        "    'out': tf.Variable(tf.random.normal([nb_classes], dtype=tf.float64))\n",
        "}\n",
        "\n",
        "f = {\n",
        "    '1': tf.nn.relu,\n",
        "    '2': tf.nn.relu,\n",
        "    'out': tf.nn.softmax\n",
        "}\n",
        "\n",
        "def runNN(x):\n",
        "    z1 = tf.add(tf.matmul(x, w['1']), b['1'])\n",
        "    a1 = f['1'](z1)\n",
        "    z2 = tf.add(tf.matmul(a1, w['2']), b['2'])\n",
        "    a2 = f['2'](z2)\n",
        "    z_out = tf.add(tf.matmul(a2, w['out']), b['out']) # a2 ovde!\n",
        "    out = f['out'](z_out)\n",
        "\n",
        "    pred = tf.argmax(out, 1)\n",
        "\n",
        "    return pred, z_out\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    epoch_loss = 0\n",
        "    nb_batches = int(nb_train / batch_size)\n",
        "    #batch je podskup trening setova\n",
        "    for i in range(nb_batches):\n",
        "        x = train_x[i*batch_size : (i+1)*batch_size, :]\n",
        "        y = y_train_manual[i*batch_size : (i+1)*batch_size]\n",
        "        y_onehot = tf.one_hot(y, nb_classes)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            _, z_out = runNN(x)\n",
        "\n",
        "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=z_out, labels=y_onehot))\n",
        "\n",
        "        w1_g, w2_g, wout_g, b1_g, b2_g, bout_g = tape.gradient(loss, [w['1'], w['2'], w['out'], b['1'], b['2'], b['out']])\n",
        "\n",
        "        opt.apply_gradients(zip([w1_g, w2_g, wout_g, b1_g, b2_g, bout_g], [w['1'], w['2'], w['out'], b['1'], b['2'], b['out']]))\n",
        "\n",
        "        epoch_loss += loss\n",
        "\n",
        "    # U svakoj epohi ispisujemo proseƒçan loss.\n",
        "    epoch_loss /= nb_train\n",
        "    print(f'Epoch: {epoch+1}/{nb_epochs}| Avg loss: {epoch_loss:.5f}')\n",
        "\n",
        "# Test!\n",
        "x = test_x\n",
        "y = y_test_manual\n",
        "\n",
        "pred, _ = runNN(x)\n",
        "pred_correct = tf.equal(pred, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float64))\n",
        "\n",
        "print(f'Test acc: {accuracy:.3f}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}